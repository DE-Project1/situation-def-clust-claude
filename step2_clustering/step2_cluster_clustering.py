# step2_cluster_clustering.py

import json
import numpy as np
from sklearn.cluster import KMeans
from bson import ObjectId
from mongo.mongo_connector import MongoConnector
from dotenv import load_dotenv

load_dotenv()

# 1. merged_vectors json íŒŒì¼ì—ì„œ ë²¡í„° ë¡œë”©
def load_vectors_from_merged_json(path: str):
    with open(path, 'r', encoding='utf-8') as f:
        merged = json.load(f)
    ids = list(merged.keys())
    vectors = np.array(list(merged.values()))
    return ids, vectors

# 2. í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼ë¥¼ MongoDBì— ì €ì¥
def upload_cluster_results_to_mongo(id_to_cluster: dict):
    mongo = MongoConnector()
    updates = []
    for _id, cluster in id_to_cluster.items():
        try:
            updates.append({
                "_id": ObjectId(_id),
                "field": "situation_cluster",
                "value": int(cluster)
            })
        except Exception as e:
            print(f"â— ObjectId ë³€í™˜ ì‹¤íŒ¨ (ID: {_id}) â†’ {e}")

    if updates:
        mongo.bulk_update_fields(updates)
        print(f"âœ… MongoDBì— í´ëŸ¬ìŠ¤í„° ê²°ê³¼ {len(updates)}ê±´ ì—…ë°ì´íŠ¸ ì™„ë£Œ")
    else:
        print("âš ï¸ ì—…ë°ì´íŠ¸í•  í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")

# 3. ì „ì²´ ì‹¤í–‰ íë¦„
if __name__ == "__main__":
    print("ğŸš€ merged_vectors.json ë¡œë”© ì¤‘...")
    ids, embeddings = load_vectors_from_merged_json("merged_vectors.json")
    print(f"âœ… ë²¡í„° ìˆ˜: {len(ids)}")

    print("ğŸ” KMeans í´ëŸ¬ìŠ¤í„°ë§ ì¤‘...")
    kmeans = KMeans(n_clusters=40, random_state=42, n_init="auto")
    labels = kmeans.fit_predict(embeddings)

    id_to_cluster = {id_: int(cluster) for id_, cluster in zip(ids, labels)}

    print("â¬†ï¸ MongoDBì— í´ëŸ¬ìŠ¤í„° ê²°ê³¼ ì—…ë¡œë“œ ì¤‘...")
    upload_cluster_results_to_mongo(id_to_cluster)
