# new_merged_vectors.npy ë°”íƒ•ìœ¼ë¡œ ë¡œì»¬ì—ì„œ í´ëŸ¬ìŠ¤í„°ë§ ì§„í–‰í•˜ê³  ê²°ê³¼ë¥¼ ì¶œë ¥í•´ë³´ëŠ” íŒŒì¼ì…ë‹ˆë‹¤.


import json
import numpy as np
from sklearn.cluster import KMeans
from bson import ObjectId
from collections import defaultdict
from mongo.mongo_connector import MongoConnector
from dotenv import load_dotenv

load_dotenv()

# 1. npy ë²¡í„° + ID json ë¶ˆëŸ¬ì˜¤ê¸°
def load_vectors_from_npy_and_ids(npy_path: str, id_path: str):
    vectors = np.load(npy_path)
    with open(id_path, 'r', encoding='utf-8') as f:
        ids = json.load(f)
    return ids, vectors

# 2. MongoDBì—ì„œ situation_definition ê°€ì ¸ì˜¤ê¸° (ì§ì ‘ fetch_documents ì‚¬ìš©)
def fetch_situation_definitions(ids):
    mongo = MongoConnector()
    object_ids = []
    for _id in ids:
        try:
            object_ids.append(ObjectId(_id))
        except Exception as e:
            print(f"â— ObjectId ë³€í™˜ ì‹¤íŒ¨: {_id} â†’ {e}")
    if not object_ids:
        return {}

    documents = mongo.fetch_documents(
        query={"_id": {"$in": object_ids}},
        projection={"situation_definition": 1}
    )

    id_to_definition = {
        str(doc["_id"]): doc.get("situation_definition")
        for doc in documents if "situation_definition" in doc
    }
    return id_to_definition

# 3. í´ëŸ¬ìŠ¤í„°ë³„ ìƒí™©ì •ì˜ ì¶œë ¥
def print_clustered_sentences(id_to_cluster, id_to_definition, sample_n=3):
    clusters = defaultdict(list)
    for _id, cluster in id_to_cluster.items():
        sentence = id_to_definition.get(_id)
        if sentence:
            clusters[cluster].append(sentence)

    print(f"\nğŸ“Š í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼ ìš”ì•½ (í´ëŸ¬ìŠ¤í„° ìˆ˜: {len(clusters)})\n")
    for cluster_id in sorted(clusters.keys()):
        print(f"ğŸ”¹ í´ëŸ¬ìŠ¤í„° {cluster_id} ({len(clusters[cluster_id])} ë¬¸ì¥)")
        for sentence in clusters[cluster_id][:sample_n]:
            print(f"   - {sentence}")
        print()

# 4. ì „ì²´ ì‹¤í–‰ íë¦„
if __name__ == "__main__":
    print("ğŸš€ ë²¡í„° ë° ID ë¡œë”© ì¤‘...")
    ids, embeddings = load_vectors_from_npy_and_ids("new_merged_vectors.npy", "ids.json")
    print(f"âœ… ë¡œë”© ì™„ë£Œ: {len(ids)}ê°œ")

    print("ğŸ” KMeans í´ëŸ¬ìŠ¤í„°ë§ ì¤‘ (n_clusters=20)...")
    kmeans = KMeans(n_clusters=20, random_state=42, n_init="auto")
    labels = kmeans.fit_predict(embeddings)
    id_to_cluster = {id_: int(cluster) for id_, cluster in zip(ids, labels)}

    print("ğŸ§² MongoDBì—ì„œ ìƒí™©ì •ì˜ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...")
    id_to_definition = fetch_situation_definitions(ids)

    print_clustered_sentences(id_to_cluster, id_to_definition, sample_n=50)
