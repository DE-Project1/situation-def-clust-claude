# step1_generate.py

from mongo.mongo_connector import MongoConnector
from step1_generate_definition.claude_api_wrapper import ClaudeAPIWrapper
from tqdm import tqdm
import asyncio
import random
import time
from collections import deque
from datetime import datetime, timedelta

from dotenv import load_dotenv
load_dotenv()

# ğŸ”§ ì´ˆë‹¹ ìš”ì²­ ìˆ˜ ì œí•œìš© RateLimiter í´ë˜ìŠ¤
class RateLimiter:
    def __init__(self, max_rps):
        self.max_rps = max_rps
        self.request_times = deque()

    async def wait(self):
        now = time.time()
        while len(self.request_times) >= self.max_rps:
            if now - self.request_times[0] > 1:
                self.request_times.popleft()
            else:
                await asyncio.sleep(0.01)
                now = time.time()
        self.request_times.append(now)


# ğŸ“Œ ê° ë¬¸ì„œ ë¹„ë™ê¸° ì²˜ë¦¬ í•¨ìˆ˜
async def process_document(cl_wrapper, doc, semaphore, rate_limiter, max_retries=3):
    async with semaphore:
        for attempt in range(1, max_retries + 1):
            try:
                await rate_limiter.wait()  # ğŸ”’ ìš”ì²­ ì†ë„ ì œí•œ
                nouns = doc["content_nouns"]
                situation = await cl_wrapper.generate_situation_async(nouns)
                return {
                    "_id": doc["_id"],
                    "field": "situation_definition",
                    "value": situation
                }
            except Exception as e:
                print(f"âš ï¸ ì˜¤ë¥˜ ë°œìƒ (id: {doc['_id']}, ì‹œë„ {attempt}): {e}")
                await asyncio.sleep(2 * attempt + random.random())
        return None


# ğŸ¯ ë©”ì¸ ì²˜ë¦¬ ë£¨í”„
async def main(batch_size: int = 32, limit: int = None, concurrency_limit: int = 30, max_rps: int = 15):
    mongo = MongoConnector()
    claude = ClaudeAPIWrapper()

    query = {
        "content_nouns": {"$exists": True, "$ne": []},
        "situation_definition": {"$exists": False}
    }
    projection = {"content_nouns": 1}
    documents = mongo.fetch_documents(query=query, projection=projection, limit=limit)

    total_docs = len(documents)
    print(f"ğŸŸ¢ ì´ ëŒ€ìƒ ë¬¸ì„œ ìˆ˜: {total_docs}")

    semaphore = asyncio.Semaphore(concurrency_limit)
    rate_limiter = RateLimiter(max_rps=max_rps)
    stats = deque()
    start_all = time.time()

    for batch_idx in tqdm(range(0, total_docs, batch_size)):
        batch = documents[batch_idx:batch_idx + batch_size]
        start_time = time.time()

        tasks = [process_document(claude, doc, semaphore, rate_limiter) for doc in batch]
        results = await asyncio.gather(*tasks)

        duration = time.time() - start_time
        updates = [res for res in results if res]

        if updates:
            mongo.bulk_update_fields(updates)

        # ì²˜ë¦¬ í†µê³„ ì €ì¥
        stats.append((datetime.now(), len(updates), duration))

        # ìµœê·¼ 10ë¶„ë§Œ ìœ ì§€
        ten_minutes_ago = datetime.now() - timedelta(minutes=10)
        while stats and stats[0][0] < ten_minutes_ago:
            stats.popleft()

        # ETA ì¶œë ¥ (5ë°°ì¹˜ë§ˆë‹¤)
        if (batch_idx // batch_size + 1) % 5 == 0:
            total_processed = sum(s[1] for s in stats)
            total_duration = sum(s[2] for s in stats)

            if total_processed > 0:
                speed = total_processed / total_duration
                remaining = total_docs - batch_idx - batch_size
                eta_minutes = (remaining / speed) / 60
                print(f"â³ ETA: ì•½ {eta_minutes:.2f}ë¶„ (ìµœê·¼ 10ë¶„ ê¸°ì¤€)")

    print("âœ… ìƒí™©ì •ì˜ ë¬¸ì¥ ì €ì¥ ì™„ë£Œ!")
    total_elapsed = time.time() - start_all
    print(f"â± ì´ ì†Œìš” ì‹œê°„: {total_elapsed / 60:.2f}ë¶„")


if __name__ == "__main__":
    asyncio.run(main())

